package com.xai.controllers;

import org.springframework.ai.chat.client.ChatClient;
import org.springframework.beans.factory.annotation.Qualifier;
import org.springframework.http.ResponseEntity;
import org.springframework.web.bind.annotation.GetMapping;
import org.springframework.web.bind.annotation.RequestMapping;
import org.springframework.web.bind.annotation.RequestParam;
import org.springframework.web.bind.annotation.RestController;

/**
 * REST controller exposing endpoints to interact with multiple LLM providers
 * (OpenAI and Ollama) using Spring AI’s {@link ChatClient}.
 *
 * <p>
 * Each {@code ChatClient} instance is backed by a different ChatModel
 * implementation. For example:
 * <ul>
 *     <li>{@code openAiChatClient} uses the {@code OpenAiChatModel} to communicate
 *     with OpenAI’s hosted LLMs.</li>
 *     <li>{@code ollamaChatClient} uses the {@code OllamaChatModel} to interact
 *     with locally hosted or self-hosted models via Ollama.</li>
 * </ul>
 * </p>
 *
 * <p>
 * This demonstrates how Spring AI enables seamless integration with multiple LLM
 * providers in the same Spring Boot application, while keeping the code minimal,
 * clean, and provider-agnostic.
 * </p>
 */
@RestController
@RequestMapping("/api/v1/chat")
public class AiController {

    /**
     * ChatClient configured to communicate with OpenAI's chat models.
     */
    private final ChatClient openAiChatClient;

    /**
     * ChatClient configured to communicate with Ollama's locally hosted models.
     */
    private final ChatClient ollamaChatClient;

    public AiController(
            @Qualifier("openAiChatClient") ChatClient openAiChatClient,
            @Qualifier("ollamaChatClient") ChatClient ollamaChatClient) {
        this.openAiChatClient = openAiChatClient;
        this.ollamaChatClient = ollamaChatClient;
    }

    /**
     * Sends a prompt to the OpenAI-backed ChatClient.
     *
     * @param prompt text input from the user
     * @return OpenAI-generated response
     */
    @GetMapping("/openAi")
    public ResponseEntity<String> askOpenAi(@RequestParam String prompt) {
        return ResponseEntity.ok(this.openAiChatClient.prompt(prompt).call().content());
    }

    /**
     * Sends a prompt to the Ollama-backed ChatClient.
     *
     * @param prompt text input from the user
     * @return response generated by the Ollama model
     */
    @GetMapping("/ollama")
    public ResponseEntity<String> askOllama(@RequestParam String prompt) {
        return ResponseEntity.ok(this.ollamaChatClient.prompt(prompt).call().content());
    }
}